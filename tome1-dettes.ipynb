{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8032669f-2e7a-4be9-a11b-9f0d8449ed2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770a1c51-9477-41f7-96aa-2e50b581bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "import pdfplumber\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabe595-4255-4fae-b7db-823933f61d00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d5d8fab3-4f01-4093-9c98-370c2cb9f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir les informations des colonnes\n",
    "def column_info(tables):\n",
    "    pattern = r\"(?<!\\d)\\d{2}-\\d{1,5}\\b\"\n",
    "    for index, list_info in enumerate(tables):\n",
    "        matches_list = []\n",
    "        for element in list_info:\n",
    "            if element:\n",
    "                matches = re.findall(pattern, element)\n",
    "                if len(matches):\n",
    "                    matches_list.append(element)\n",
    "        if not len(matches_list):\n",
    "            return index\n",
    "\n",
    "# Fonction pour générer les noms de colonnes\n",
    "def column_names_generate(tables, index_col_table):\n",
    "    col_name_list = []\n",
    "    zip_list = [list(element) for element in zip(*tables[0:index_col_table])]\n",
    "    for index, col in enumerate(zip_list): # col 0 is\n",
    "        # Repeat the subcolumn names\n",
    "        if not col[0]:\n",
    "            for index_e, e in enumerate(col):\n",
    "                following_values = all(pd.Series(col[index_e:]).isna()) \n",
    "                if (not e) and (not following_values):\n",
    "                    zip_list[index][index_e] = zip_list[index-1][index_e]\n",
    "        cleaned_list = ['' if not x else x.replace(\"\\n\", \" \") for x in col]\n",
    "        col_name_list.append(\" \".join(cleaned_list))\n",
    "    col_name_list = [col_name.lstrip().rstrip() if col_name else col_name for col_name in col_name_list]\n",
    "    return col_name_list\n",
    "\n",
    "def lambda_correct(text, repeat_n):\n",
    "    text_f = \"\"\n",
    "    for carac in range(0, len(text), repeat_n):\n",
    "        text_f += text[carac]\n",
    "    return text_f\n",
    "\n",
    "def correct_bold_text_double(df):\n",
    "    df_copy = df.copy()\n",
    "    col_to_correct = []\n",
    "    for col in df_copy.columns:\n",
    "        counter = 0\n",
    "        for e in df_copy[col]:\n",
    "            if \",,\" in e:\n",
    "                counter += 1\n",
    "        if counter:\n",
    "            col_to_correct.append(col)\n",
    "    for col in col_to_correct:\n",
    "        df_copy[col] = df_copy[col].apply(lambda x: lambda_correct(x, 2))\n",
    "    return df_copy\n",
    "\n",
    "def correct_bold_text_triple(df):\n",
    "    df_copy = df.copy()\n",
    "    col_to_correct = []\n",
    "    for col in df_copy.columns:\n",
    "        counter = 0\n",
    "        for e in df_copy[col]:\n",
    "            if \",,,\" in e:\n",
    "                counter += 1\n",
    "        if counter:\n",
    "            col_to_correct.append(col)\n",
    "    for col in col_to_correct:\n",
    "        df_copy[col] = df_copy[col].apply(lambda x: lambda_correct(x, 3))\n",
    "    return df_copy\n",
    "    \n",
    "def flag_depense_recette(df, current_ope):\n",
    "    df_copy = df.copy()\n",
    "    depense_row = df_copy[df_copy.iloc[:,0]==\"DEPENSES\"]\n",
    "    recette_row = df_copy[df_copy.iloc[:,0]==\"RECETTES\"]\n",
    "    title_col = \"type_opération\"\n",
    "    depense_txt = \"Dépense\"\n",
    "    recette_txt = \"Recette\"\n",
    "    if len(depense_row) and not len(recette_row):\n",
    "        df_copy[title_col] = depense_txt\n",
    "        current_ope = depense_txt\n",
    "        df_copy.drop(index=depense_row.index[0], inplace=True)\n",
    "    elif len(depense_row) and len(recette_row):\n",
    "        df_copy[title_col] = np.where(\n",
    "            (df_copy.index > depense_row.index[0]) & (df_copy.index < recette_row.index[0]),\n",
    "            depense_txt,\n",
    "            recette_txt\n",
    "        )\n",
    "        current_ope = recette_txt\n",
    "        df_copy.drop(index=[depense_row.index[0], recette_row.index[0]], inplace=True)\n",
    "    elif not len(depense_row) and len(recette_row):\n",
    "        df_copy[title_col] = np.where(\n",
    "            df_copy.index < recette_row.index[0],\n",
    "            depense_txt,\n",
    "            recette_txt\n",
    "        )\n",
    "        current_ope = recette_txt\n",
    "        df_copy.drop(index=recette_row.index[0], inplace=True)\n",
    "    else:\n",
    "        df_copy[title_col] = current_ope\n",
    "    return df_copy, current_ope\n",
    "            \n",
    "# Paramètres pour l'extraction avec pdfplumber\n",
    "params = {\n",
    "    \"vertical_strategy\": \"explicit\",\n",
    "    \"horizontal_strategy\": \"explicit\",\n",
    "    \"explicit_vertical_lines\": [],\n",
    "    \"explicit_horizontal_lines\": [],\n",
    "    \"snap_tolerance\": 100,\n",
    "    \"snap_x_tolerance\": 3,\n",
    "    \"snap_y_tolerance\": 3,\n",
    "    \"join_tolerance\": 3,\n",
    "    \"join_x_tolerance\": 2000,\n",
    "    \"join_y_tolerance\": 0,\n",
    "    \"edge_min_length\": 3,\n",
    "    \"min_words_vertical\": 3,\n",
    "    \"min_words_horizontal\": 3,\n",
    "    \"intersection_tolerance\": 15,\n",
    "    \"intersection_x_tolerance\": 3,\n",
    "    \"intersection_y_tolerance\": 3,\n",
    "    \"text_tolerance\": 1,\n",
    "    \"text_x_tolerance\": 3,\n",
    "    \"text_y_tolerance\": 3,\n",
    "}\n",
    "\n",
    "section_dict = {\n",
    "    \"Invest\": \"Section d'investissement\",\n",
    "    \"Fonct\": \"Section de fonctionnement\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6a77a-6971-4d20-9c6a-ba5674f139f6",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb4b8ff-e47c-413e-b6b0-bf43b9a496e1",
   "metadata": {},
   "source": [
    "## Tome 1 - Annexes hors dettes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa69a4d-b5c3-4011-b4ad-2ef660a97f70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51a8ff53-d56d-452c-9f71-07b97289e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_tome1_dettes(folder_path, year, files_dict, min_page, max_page, text_col, num_col):\n",
    "    \n",
    "    # Defining path\n",
    "    path_pdf = os.path.join(folder_path, files_dict[year])\n",
    "\n",
    "    # Initialisation final df\n",
    "    final_df = pd.DataFrame()\n",
    "    \n",
    "    # Opening PDF\n",
    "    with pdfplumber.open(path_pdf) as pdf:\n",
    "        \n",
    "        # Parcourir chaque page\n",
    "        for page_num in range(min_page, max_page):\n",
    "            if page_num in (min_page, max_page-1) or page_num%5 == 0:\n",
    "                print(page_num)\n",
    "                \n",
    "            # Lire le tableau\n",
    "            page = pdf.pages[page_num]\n",
    "            params[\"explicit_vertical_lines\"] = page.curves + page.edges\n",
    "            params[\"explicit_horizontal_lines\"] = page.curves + page.edges\n",
    "            tables = page.extract_table(table_settings=params)\n",
    "\n",
    "            if tables: #Des pages peuvent être vides\n",
    "\n",
    "                # Obtenir l'index des tables où les colonnes commencent\n",
    "                col_index = 3\n",
    "        \n",
    "                # Générer les noms des colonnes\n",
    "                col_names = column_names_generate(tables, col_index)\n",
    "        \n",
    "                # Générer le DataFrame\n",
    "                df = pd.DataFrame(tables[col_index:], columns=col_names)\n",
    "    \n",
    "                # Corrections des éventuelles lignes en gras\n",
    "                df = correct_bold_text_triple(df)\n",
    "                df = correct_bold_text_double(df)\n",
    "    \n",
    "                # Ajout colonne\n",
    "                df.insert(0, \"Numéro_page\", page_num + 1)\n",
    "                \n",
    "                # Concatenation\n",
    "                final_df = pd.concat([final_df, df])\n",
    "\n",
    "    # Cleaning\n",
    "    for col in text_col:\n",
    "        final_df.iloc[:,col] = final_df.iloc[:,col]\\\n",
    "            .str.replace(\"\\n\",\" \")\\\n",
    "            .str.replace(\"(cid:176)\",\"°\")\\\n",
    "            .str.replace(\"Ø\",\"é\")\\\n",
    "            .str.replace(\"(cid:244)\",\"ô\")\\\n",
    "            .str.replace(\"(cid:224)\",\"à\")\\\n",
    "            .str.replace(\"(cid:226)\",\"â\")\\\n",
    "            .str.replace(\"(cid:231)\",\"ç\")\\\n",
    "            .str.replace(\"Ł\",\"è\")\n",
    "    for col in num_col:\n",
    "        final_df.iloc[:,col] = final_df.iloc[:,col].apply(lambda x: float(x.replace(\" \",\"\").replace(\",\",\".\").replace(\"\\n\",\"\")) if len(x) else x)\n",
    "    final_df.columns = final_df.columns\\\n",
    "        .str.replace(\"(cid:176)\",\"°\")\\\n",
    "        .str.replace(\"Ø\",\"é\")\\\n",
    "        .str.replace(\"(cid:244)\",\"ô\")\\\n",
    "        .str.replace(\"(cid:224)\",\"à\")\\\n",
    "        .str.replace(\"(cid:226)\",\"â\")\\\n",
    "        .str.replace(\"(cid:231)\",\"ç\")\\\n",
    "        .str.replace(\"Ł\",\"è\")\\\n",
    "        .str.replace('(cid:146)',\"'\")\\\n",
    "        .str.replace(\"Œ\",\"ê\")\\\n",
    "        .str.replace(\"ß\",\"û\")\n",
    "    \n",
    "    # Ajout nom fichier\n",
    "    final_df.insert(0, \"Fichier_source\", files_dict[year])\n",
    "    final_df.insert(0, \"Année\", year)\n",
    "    \n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2efdef-0f3b-45cd-b626-2e90815f0c73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3daac443-0075-46e5-928b-2f0147a0b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le chemin du fichier PDF\n",
    "folder_path = os.path.join(\"sources\", \"Tome_1\")\n",
    "\n",
    "# Creation dictionnaire fichiers\n",
    "files_dict = {\n",
    "    2023: \"CA 2023 - Budget général Compte sur chiffres et annexes Tome 1.pdf\",\n",
    "    2022: \"02 - CA 2022 Budget général - Compte sur chiffres et annexes - Tome 1.pdf\",\n",
    "    2021: \"CA 2021 - Tome 1.pdf\",\n",
    "    2020: \"04 Document budgétaire (Tome 1).pdf\",\n",
    "    2019: \"04 - Document budgétaire (Tome 1.1).pdf\"\n",
    "}\n",
    "\n",
    "files_dict_spec = {\n",
    "    2022: \"03 - CA 2022 Budget général - Compte sur chiffres et annexes - Tome 2.pdf\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c606fed-f6cc-409f-b047-668368e47675",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "610fc8b7-8ac4-4b38-ab45-3ac9bf084d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b2e2b06-1486-4d57-aaa1-9c6e50e5151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "250\n",
      "253\n",
      "254\n",
      "255\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "year = 2023\n",
    "all_df[f\"Tome 1_{year}_Dettes_1\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 248, max_page = 254, text_col = [1, 2, 8], num_col = [6, 9, 10])\n",
    "all_df[f\"Tome 1_{year}_Dettes_2\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 254, max_page = 259, text_col = [1, 8], num_col = [3, 5, 6, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "680e6ffb-054c-4ad0-b596-321de4c32cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "10\n",
      "12\n",
      "13\n",
      "15\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "year = 2022\n",
    "all_df[f\"Tome 2_{year}_Dettes_1\"] = main_tome1_dettes(os.path.join(\"sources\", \"Tome_2\"), year, files_dict_spec, min_page = 7, max_page = 13, text_col = [1, 2, 8], num_col = [6, 9, 10])\n",
    "all_df[f\"Tome 2_{year}_Dettes_2\"] = main_tome1_dettes(os.path.join(\"sources\", \"Tome_2\"), year, files_dict_spec, min_page = 13, max_page = 18, text_col = [1, 8], num_col = [3, 5, 6, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05136e9a-9b9e-4239-8da3-bd3b569c96cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "240\n",
      "243\n",
      "244\n",
      "245\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "year = 2021\n",
    "all_df[f\"Tome 1_{year}_Dettes_1\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 239, max_page = 244, text_col = [1, 2, 8], num_col = [6, 9, 10])\n",
    "all_df[f\"Tome 1_{year}_Dettes_2\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 244, max_page = 249, text_col = [1, 8], num_col = [3, 5, 6, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2bb0cd03-52a7-4875-949c-1fbe0089f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "245\n",
      "246\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "year = 2020\n",
    "all_df[f\"Tome 1_{year}_Dettes_1\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 241, max_page = 246, text_col = [1, 2, 8], num_col = [6, 9, 10])\n",
    "all_df[f\"Tome 1_{year}_Dettes_2\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 246, max_page = 251, text_col = [1, 8], num_col = [3, 5, 6, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811319f-5f80-48c3-b9f0-b8b91e171915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c5c4b78-ac21-405d-9531-f0e8dc5b64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "265\n",
      "267\n",
      "269\n",
      "270\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "all_df[f\"Tome 1_{year}_Dettes_1\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 263, max_page = 268, text_col = [1, 2, 8], num_col = [6, 9, 10])\n",
    "all_df[f\"Tome 1_{year}_Dettes_2\"] = main_tome1_dettes(folder_path, year, files_dict, min_page = 269, max_page = 274, text_col = [1, 8], num_col = [3, 5, 6, 9, 10, 11, 12, 13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44220611-95ca-4c5f-bdaa-00876ff90973",
   "metadata": {},
   "source": [
    "### Concatenating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e331e545-2436-404a-944c-7605b329390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_1 = pd.DataFrame()\n",
    "final_df_2 = pd.DataFrame()\n",
    "for key, df in all_df.items():\n",
    "    df.columns = df.columns.str.replace(\"’\",\"'\")\n",
    "    df.columns = df.columns.str.replace(\"''\",\"'\")\n",
    "    if key.endswith(\"_1\"):\n",
    "        final_df_1 = pd.concat([final_df_1, df])\n",
    "    else:\n",
    "        for num in range(10, 18):\n",
    "            df.columns = df.columns.str.replace(f\"({num})\",\"\")\n",
    "        final_df_2 = pd.concat([final_df_2, df])\n",
    "final_df_1.reset_index(drop=True, inplace=True)\n",
    "final_df_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c85cd35-f0a9-45e9-91a2-24c025d5fee5",
   "metadata": {},
   "source": [
    "### Excel extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "59392bc3-1ba6-4e03-9ff0-3022c22d7ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"Tome 1_2019-2023_Répartition_Dettes.xlsx\"\n",
    "with pd.ExcelWriter(file_name, engine='xlsxwriter') as writer:\n",
    "    final_df_1.to_excel(writer, sheet_name=\"Dette_Repart\", index=False)\n",
    "    final_df_2.to_excel(writer, sheet_name=\"Dette_Repart_B1_2\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
